# Настройка подключения к ВМ
ssh -i ~/.ssh/yandex_cloud_new ubuntu@62.84.116.137 # для запуска подключения к виртуалке

## Создание ВМ, регистри и кластера
terraform init
terraform plan
terraform apply
terraform output external_ip # для получения ip виртуалки
# после апплая
terraform output -raw vm_public_ip
ssh -i ~/.ssh/yandex_cloud ubuntu@$(terraform output -raw vm_public_ip)



## Для обновления registry-id
# Полностью выйти из всех registry
docker logout
# Удалить все образы, связанные со старым registry
docker images | grep 'старый-id-реестра' | awk '{print $3}' | xargs docker rmi -f
# Авторизоваться заново
yc container registry configure-docker



## Абстрактные инструкции
yc iam create-token  -  создание токена
# nat_ip_address     = yandex_vpc_address.static_ip.external_ipv4_address[0].address  -  добавить в network_interface {}

yc container registry configure-docker # Авторизация в Container Registry



## Передача образов в регистри
./docker-build-and-push.sh



## Запуск подов
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/mysql.yaml
kubectl apply -f k8s/backend.yaml
kubectl apply -f k8s/frontend.yaml

# Создаем пространство имен для мониторинга
kubectl apply -f k8s/monitoring-namespace.yaml

# Применяем RBAC для Prometheus
kubectl apply -f k8s/prometheus-rbac.yaml

# Применяем конфигурацию Prometheus
kubectl apply -f k8s/prometheus-config.yaml

# Разворачиваем Prometheus
kubectl apply -f k8s/prometheus-deployment.yaml

# Настраиваем источник данных для Grafana
kubectl apply -f k8s/grafana-datasource-config.yaml

# Применяем дашборды Grafana
kubectl apply -f k8s/grafana-dashboards.yaml

# Разворачиваем Grafana
kubectl apply -f k8s/grafana-deployment.yaml



# Получение нод для получения external-ip для grafana
kubectl get nodes -o wide



# Получение EXTERNAL-IP
kubectl -n task-manager get svc frontend -o wide



## Перезагрузка пода
kubectl -n task-manager rollout restart deployment/backend
kubectl -n task-manager rollout status deployment/backend


## Перезагрузка пода с imagePullPolicy: IfNotPresent через иммутабельные теги
kubectl -n task-manager set image deployment/backend backend=cr.yandex/crpvgh0sslbb16bufevk/task-manager-backend:<NEW_TAG> --record


## Мониторинг: установка kube-prometheus-stack (Prometheus + Grafana)
# Установка через Helm в namespace monitoring
kubectl create ns monitoring || true
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
helm upgrade --install kps prometheus-community/kube-prometheus-stack -n monitoring

# Проверить HPA
kubectl -n task-manager get hpa backend-hpa
kubectl -n task-manager get hpa backend-hpa -w

# Дать нагрузку (пример с hey)
# brew install hey
hey -z 60s -c 50 http://<EXTERNAL_IP_OR_LB>/api/health # hey -z 60s -c 50 http://89.169.141.236:30001/api/health

# Наблюдать рост реплик бэкенда
kubectl -n task-manager get deploy backend -w


## Пересборка бэкенда после добавления метрик
# Требуется пересобрать и запушить образ из-за добавления prom-client и /metrics
cd backend && npm ci && cd -
./docker-build-and-push.sh
kubectl -n task-manager rollout restart deployment/backend
